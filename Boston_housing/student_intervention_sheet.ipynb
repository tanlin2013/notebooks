{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-Y8KALF__YL"
   },
   "source": [
    "## Supervised Learning\n",
    "## Project: Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T598GfQ0__YM"
   },
   "source": [
    "This is a revised veriosn of the project from Udacity Machine Learning Engineer Nanodegree. In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a `'TODO'` statement. Please be sure to read the instructions carefully!\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.  \n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvOtJxkQfx3Z"
   },
   "source": [
    "This project requires **Python** and the following Python libraries installed:\n",
    "\n",
    "- [NumPy](http://www.numpy.org/)\n",
    "- [Pandas](http://pandas.pydata.org)\n",
    "- [matplotlib](http://matplotlib.org/)\n",
    "- [scikit-learn](http://scikit-learn.org/stable/) version: 0.18+\n",
    "\n",
    "You will also need to have software installed to run and execute a [Jupyter Notebook](https://jupyter.org/install)\n",
    "\n",
    "If you do not have Python installed yet, it is highly recommended that you install the [Anaconda](https://www.anaconda.com/distribution/) distribution of Python, which already has the above packages and more stuff included.\n",
    "\n",
    "Or, you can put this file on the [Google colab](https://colab.research.google.com/) environment. It's a free Jupyter notebook environment that requires no setup and runs entirely on the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y48EFfpQ__YN"
   },
   "source": [
    "### **Question 1** - Classification vs. Regression\n",
    "*Your goal for this project is to identify students who might need early intervention before they fail to graduate. Which type of supervised learning problem is this, classification or regression? Why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUxh6NQh__YP"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mLOmnB8__YQ"
   },
   "source": [
    "## Exploring the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5ps9hi6BL8T"
   },
   "source": [
    "If you are opening this notebook with Google colab, you have to put the necessary file (student-data.csv) in your drive and mount the drive. Otherwise, simply put the file in the same local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LB0_miGHAIzS"
   },
   "outputs": [],
   "source": [
    "# mount your google drive if you're using colab and put your csv file on your google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXayPivjBFy_"
   },
   "source": [
    "Run the code cell below to load necessary Python libraries and load the student data. Note that *the last column from this dataset*, `'passed'`, will be our *target* label (whether the student graduated or didn't graduate). All other columns are *features* about each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OYppUez__YR"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "\n",
    "# Read student data\n",
    "student_data = pd.read_csv(\"{YOUR_FILE_LOCATION}\")\n",
    "print(\"Student data read successfully!\")\n",
    "\n",
    "display(student_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqNqE6ngEI-3"
   },
   "source": [
    "This dataset has the following attributes:\n",
    "- school : student's school (binary: \"GP\" or \"MS\")\n",
    "- sex : student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "- age : student's age (numeric: from 15 to 22)\n",
    "- address : student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "- famsize : family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "- Pstatus : parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "- Medu : mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "- Fedu : father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "- Mjob : mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- Fjob : father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "- reason : reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "- guardian : student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "- traveltime : home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "- studytime : weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "- failures : number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "- schoolsup : extra educational support (binary: yes or no)\n",
    "- famsup : family educational support (binary: yes or no)\n",
    "- paid : extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "- activities : extra-curricular activities (binary: yes or no)\n",
    "- nursery : attended nursery school (binary: yes or no)\n",
    "- higher : wants to take higher education (binary: yes or no)\n",
    "- internet : Internet access at home (binary: yes or no)\n",
    "- romantic : with a romantic relationship (binary: yes or no)\n",
    "- famrel : quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "- freetime : free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "- goout : going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "- Dalc : workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- Walc : weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "- health : current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "- absences : number of school absences (numeric: from 0 to 93)\n",
    "- passed : did the student pass the final exam (binary: yes or no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0220kk9QEmxZ"
   },
   "source": [
    "### **Question 2** - Guess important features\n",
    "Before making any observations about the data, *from your intuition*, which **three** features do you believe to be most important for prediction, and in what order would you rank them and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvZJTDXgFt2G"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeDJwh8v__YW"
   },
   "source": [
    "### Implementation: Data Exploration\n",
    "Let's begin by investigating the dataset to determine how many students we have information on, and learn about the graduation rate among these students.\n",
    "In the code cell below, you will need to compute the following:\n",
    "- The total number of students, `n_students`.\n",
    "- The total number of features for each student, `n_features`.\n",
    "- The number of those students who passed, `n_passed`.\n",
    "- The number of those students who failed, `n_failed`.\n",
    "- The graduation rate of the class, `grad_rate`, in percent (%).  \n",
    "\n",
    "Do not fill in **fixed numbers** for these variables. Try to extract them with some functions or from other variables.  \n",
    "*hint: use* `student_data.shape` *to see the dimension of the student matrix.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7g4EiqTF5hh"
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate number of students\n",
    "n_students = None\n",
    "\n",
    "# TODO: Calculate number of features\n",
    "n_features = None\n",
    "\n",
    "# TODO: Calculate passing students\n",
    "n_passed = None\n",
    "\n",
    "# TODO: Calculate failing students\n",
    "n_failed = None\n",
    "\n",
    "# TODO: Calculate graduation rate\n",
    "grad_rate = None\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of students: {}\".format(n_students))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of students who passed: {}\".format(n_passed))\n",
    "print(\"Number of students who failed: {}\".format(n_failed))\n",
    "print(\"Graduation rate of the class: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ks5vqSz__Yb"
   },
   "source": [
    "## Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains **non-numeric** features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with. There are some features that contain non-numeric values, we have to take a look at them first.  \n",
    "Run the code cell below to separate the student data into feature and target columns to see if any features are non-numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eua8TONJ__Yc"
   },
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "# The last column is the target so we ignore it.\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns are:\\n{}\".format(feature_cols))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = student_data[feature_cols]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "display(X_all[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDVtSbIT6cAy"
   },
   "source": [
    "### **Question 3** - Explore non-numeric data\n",
    "*Point out the non-numeric features. What features have two different values? What features contain more than two possibilities?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVuZuMi260fu"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvuoHEwf__Ye"
   },
   "source": [
    "### Preprocess Feature Columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted. Before data can be used as input for machine learning algorithms, we have to \"reformat\" or \"restructure\" some data — this is typically known as **preprocessing**.  For example, columns with `yes`/`no` can be reasonably converted into `1`/`0` (binary) values. Becasue we want to predict whether a student can pass or not, the target variable can be converted to `1`/`0` where 0 means **\"did not pass\"**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mpkkj3JQJ1Ey"
   },
   "outputs": [],
   "source": [
    "# Extract target column 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "# Convert the binary result yes/no to 1/0\n",
    "y_all = student_data[target_col].replace({'yes':1, 'no':0})\n",
    "print(\"Target column is: {}\".format(target_col))\n",
    "# list five rows\n",
    "display(y_all[:5].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pw7n3_g2Luxn"
   },
   "source": [
    "Other columns which have more than two values are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation. Run the code cell below to perform the preprocessing routine discussed in this section.\n",
    "\n",
    "> **Note**: this trick is called [*one-hot encoding*](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) and it is used very often in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxqgiT-K__Yf"
   },
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace their values(e.g. yes/no) with 1/0        \n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace({'yes':1, 'no':0})\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace({'M':1, 'F':0})\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace({'GP':1, 'MS':0})\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace({'R':1, 'U':0})\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace({'A':1, 'T':0})\n",
    "            \n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UP_nZGn2PJ73"
   },
   "source": [
    "You can use `display()` to see `X_all` after the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMuy5OrLPJVu"
   },
   "outputs": [],
   "source": [
    "display(X_all[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkCVZyfQ__Yi"
   },
   "source": [
    "### Implementation: Training and Testing Data Split\n",
    "So far, we have converted all _categorical_ features into numeric values. For the next step, we split the data (both features and corresponding labels) into training and test sets. In the following code cell below, you will need to implement the following:\n",
    "- Randomly shuffle and split the data (`X_all`, `y_all`) into training and testing subsets.\n",
    "  - Use **300** training points (approximately 75%) and the rest are testing points (approximately 25%).\n",
    "  - Set a `random_state` for the function(s) you use, if provided.\n",
    "  - Store the results in `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "In general, you can use the function `sklearn.model_selection.train_test_split` to achieve this. However, please **do not use this function in the cell below**. Use `sklearn.utils.shuffle` and set the number of training samples on your own. Please refer to [scikit learn webpage](http://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html) to see the usage of the shuffle function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqFXGnW9FyVQ"
   },
   "outputs": [],
   "source": [
    "# TODO: import required module\n",
    "\n",
    "# TODO: Set the number of training points\n",
    "num_train = None\n",
    "\n",
    "# Set the number of testing points\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "y_train = y_all[:num_train]\n",
    "y_test = y_all[num_train:]\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpwdDuKX__Yl"
   },
   "source": [
    "## Training and Evaluating Models\n",
    "In this section, you have to choose 3 supervised learning models that are appropriate for this problem and available in `scikit-learn`. You will first discuss the reasoning behind choosing these three models by considering what you know about the data and each model's strengths and weaknesses. You will then fit the model to varying sizes of training data (100 data points, 200 data points, and 300 data points) and measure the F<sub>1</sub> score. You will need to produce three tables (one for each model) that shows the training set size, training time, prediction time, F<sub>1</sub> score on the training set, and F<sub>1</sub> score on the testing set.\n",
    "\n",
    "**The following supervised learning models are currently available in** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **that you may choose from:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression\n",
    "- Perceptron\n",
    "\n",
    "> **Note**: not every model was introduced in this class. Some of them will be discussed in the latter course. Try tor read the documents and understand them by yourself (at least, know how to use them correctly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtS3Fwfk__Ym"
   },
   "source": [
    "### **Question 4** - Model Application\n",
    "List **three** supervised learning models that are appropriate for this problem. For **each model** chosen, answer the following questions\n",
    "- Describe one real-world application in industry where the model can be applied. *(You may need to do a small bit of research for this — give references!)* \n",
    "- What are the strengths of the model; when does it perform well? \n",
    "- What are the weaknesses of the model; when does it perform poorly?\n",
    "- What makes this model a good candidate for the problem, given what you know about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Amra2Fw7__Yn"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbmBC6hl__Yo"
   },
   "source": [
    "### Setup\n",
    "Run the code cell below to initialize three helper functions which you can use for training and testing the three supervised learning models you've chosen above. The functions are as follows:\n",
    "- `train_classifier` - takes as input a classifier and training data and fits the classifier to the data.\n",
    "- `predict_labels` - takes as input a fit classifier, features, and a target labeling and makes predictions using the F<sub>1</sub> score.\n",
    "- `train_predict` - takes as input a classifier, and the training and testing data, and performs `train_clasifier` and `predict_labels`.\n",
    " - This function will report the F<sub>1</sub> score for both the training and testing data separately.\n",
    " \n",
    "Here we use the [`time`](https://docs.python.org/3/library/time.html) module to estimate the execution time of each process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_n8VZAEU__Yp"
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print(\"Made predictions in {:.6f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target.values, y_pred)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"F1 score for training set: {:.6f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"F1 score for test set: {:.6f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0l2OFvn__Ys"
   },
   "source": [
    "### Implementation: Model Performance Metrics\n",
    "With the predefined functions above, you will now import the three supervised learning models of your choice and run the `train_predict` function for each one. *Remember that you will need to train and predict on each classifier for three different training set sizes: 100, 200, and 300.* Hence, you should expect to have 9 different outputs below — 3 for each model using the varying training set sizes. In the following code cell, you will need to implement the following:\n",
    "- Import the three supervised learning models you've discussed in the previous section.\n",
    "- Initialize the three models and store them in `clf_A`, `clf_B`, and `clf_C`.\n",
    " - Use a `random_state` for each model you use, **if provided**.\n",
    " - **Note:** Use the default settings for each model — you will tune one specific model in a later section.\n",
    "- Create the different training set sizes to be used to train each model.\n",
    " - *Do not reshuffle and resplit the data! The new training points should be drawn from `X_train` and `y_train`.*\n",
    "- Fit each model with each training set size and make predictions on the test set (9 in total).  \n",
    " - **Note1:** Three tables are provided after the following code cell which can be used to store your results.\n",
    " - **Note2:** You could try to use different parameters for each model to get better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nClltJQO__Yt"
   },
   "outputs": [],
   "source": [
    "# TODO: Import the three supervised learning models from sklearn\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = None\n",
    "clf_B = None\n",
    "clf_C = None\n",
    "\n",
    "# TODO: Set up the training set sizes\n",
    "X_train_100 = None\n",
    "y_train_100 = None\n",
    "\n",
    "X_train_200 = None\n",
    "y_train_200 = None\n",
    "\n",
    "X_train_300 = None\n",
    "y_train_300 = None\n",
    "\n",
    "# TODO: Execute the 'train_predict' function written above for each classifier and each training set size\n",
    "train_predict(clf_A, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWPoOSch__Yx"
   },
   "source": [
    "### Tabular Results\n",
    "Edit the cell below to see how a table can be designed in [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Fill your results from above in the tables provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRrn1sfn__Yy"
   },
   "source": [
    "** Classifer 1 - {YOUR_FIRST_CLASSIFIER}**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |                         |                        |                  |                 |\n",
    "| 200               |                  |                     |                  |                 |\n",
    "| 300               |                         |                        |               |              |\n",
    "\n",
    "** Classifer 2 - {YOUR_SECOND_CLASSIFIER}**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |                         |                        |                  |                 |\n",
    "| 200               |     EXAMPLE             |                        |                  |                 |\n",
    "| 300               |                         |                        |                  |     EXAMPLE     |\n",
    "\n",
    "** Classifer 3 - {YOUR_THIRD_CLASSIFIER}**  \n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | F1 Score (train) | F1 Score (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 100               |                         |                        |                  |                 |\n",
    "| 200               |                         |                        |                  |                 |\n",
    "| 300               |                         |                        |                  |                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZNqyU5w__Yy"
   },
   "source": [
    "## Choosing the Best Model\n",
    "In this final section, you will choose from the three supervised learning models the *best* model to use on the student data. You will then fine tune the chosen by performing a grid search optimization for the model over the entire training set (`X_train` and `y_train`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEbPMrOl__Yz"
   },
   "source": [
    "### **Question 5** - Choosing the Best Model\n",
    "Based on the experiments you performed earlier, in one to two paragraphs, explain what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?  \n",
    ">*hint: think about which model is better if you do not have enough training points.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PPer5LA__Y0"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIc_i6w1__Y1"
   },
   "source": [
    "### **Question 6** - Explain your idea\n",
    "In one to two paragraphs, explain in [**layman's terms**](https://www.urbandictionary.com/define.php?term=layman%27s%20terms) how the final model chosen is supposed to work. More specifically, *explain your idea through which an average person who has made no in depth study of the topic will understand the basic concept being described*. Be sure that you are describing the major qualities of the model, such as how the model is trained and how the model makes a prediction.(for example, if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).  *Avoid using advanced mathematical or technical jargon*, such as describing equations or discussing the algorithm implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4763lL4g__Y2"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hq_lH5Ny__Y3"
   },
   "source": [
    "### Implementation: Model Tuning\n",
    "Here we use grid search method to fine tune the chosen model. Briefly, grid search is a brute force method to estimate hyperparameters. \n",
    "\n",
    "Use grid search (`GridSearchCV`) with at least one important parameter tuned with at least 3 different values. You will need to use the entire training set for this. In the code cell below, you will need to implement the following:\n",
    "- Import [`sklearn.model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "- Create a dictionary of parameters you wish to tune for the chosen model.\n",
    " - Example: `parameters = {'parameter' : [list of values]}`.\n",
    "- Initialize the classifier you've chosen and store it in `clf`.\n",
    " - Set the `pos_label` parameter to the correct value!\n",
    "- Perform grid search on the classifier `clf` using `f1_score` as the scoring method, and store it in `grid_obj`.\n",
    "- Fit the grid search object to the training data (`X_train`, `y_train`), and store it in `grid_obj`.\n",
    "\n",
    "hint: you should read this [tutorial](https://scikit-learn.org/stable/modules/grid_search.html) first if you do not know what grid search is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlpcr6O-__Y3"
   },
   "outputs": [],
   "source": [
    "# TODO: Import 'GridSearchCV'\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "# for example, parameters for a decision tree regressor can be {'max_depth':(2,3,4)} \n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "\n",
    "# TODO: create a scorer which use f1_score\n",
    "\n",
    "# TODO: Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print(grid_obj.best_params_)\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print(\"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print(\"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Se7Azoag__Y6"
   },
   "source": [
    "### Question 7 - Final F<sub>1</sub> Score\n",
    "*What is the final model's F<sub>1</sub> score for training and testing? How does that score compare to the untuned model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xq2jSUQI__Y6"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AqTm3nJ9W-r"
   },
   "source": [
    "### **Question 8** - Normalizing Numerical Features\n",
    "*According to the model you choose in Question 5, is it neccessary to normalize those numerical features? Why or why not?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7emMvW_d-Ktk"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FflbMDJL_Xl8"
   },
   "source": [
    "### Feature Importance  \n",
    "An important task when performing supervised learning on a dataset we study here is determining which features provide the most predictive power. By focusing on the relationship between only a few crucial features and the target label we simplify our understanding of the phenomenon, which is most always a useful thing to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YFmFDzq_vo9"
   },
   "source": [
    "### Implementation - Extracting Feature Importance\n",
    "\n",
    "Some classifiers (for example, the decision tree classifier) in sci-kit learn package have a *feature_importance_* attribute, which ranks the importance of features according to the chosen classifier.  \n",
    "In the code cell below, you will need to implement the following:\n",
    "- Import a decision tree classifier.\n",
    "- Train the supervised model on the entire training set (i.e. `X_train`).\n",
    "- Set the parameter `max_depth` to 5.\n",
    "- Extract the feature importances using `feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM7uUOeA_tH9"
   },
   "outputs": [],
   "source": [
    "# TODO: Import a decision tree model that has 'feature_importances_'\n",
    "\n",
    "# TODO: Train the supervised model on the training set \n",
    "\n",
    "# TODO: Extract the feature importances\n",
    "importances = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "louZTNHfF8vU"
   },
   "source": [
    "Here we provide you a helper function which can visualize the top five importance of features. Run the cell below to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8PJ_WxzCiuS"
   },
   "outputs": [],
   "source": [
    "def feature_plot(importances, X_train, y_train):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    # Display the five most important features\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    columns = X_train.columns.values[indices[:5]]\n",
    "    values = importances[indices][:5]\n",
    "\n",
    "    # Creat the plot\n",
    "    fig = plt.figure(figsize = (9,5))\n",
    "    plt.title(\"Normalized Weights for First Five Most Predictive Features\", fontsize = 16)\n",
    "    plt.bar(np.arange(5), values, width = 0.6, align=\"center\", color = 'b', \\\n",
    "          label = \"Feature Weight\")\n",
    "    plt.bar(np.arange(5) - 0.3, np.cumsum(values), width = 0.2, align = \"center\", color = 'g', \\\n",
    "          label = \"Cumulative Feature Weight\")\n",
    "    plt.xticks(np.arange(5), columns)\n",
    "    plt.xlim((-0.5, 4.5))\n",
    "    plt.ylabel(\"Weight\", fontsize = 12)\n",
    "    plt.xlabel(\"Feature\", fontsize = 12)\n",
    "    \n",
    "    plt.legend(loc = 'upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "\n",
    "feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbnq7-QbGYQC"
   },
   "source": [
    "### **Question 9** - Extract Important Features\n",
    "How do these five features compare to the features you discussed in Question 2? If you were close to the same answer, how does this visualization confirm your thoughts? If you were not close, why do you think those features are more relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGeIcRf3Gnxm"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phASE2_dHxmH"
   },
   "source": [
    "### Implementation - Feature Selection\n",
    "How does a model perform if we only use a subset of all the available features in the data? From the visualization above, we see that the top five most important features contribute most of the importance of all features present in the data. This indicates that we can attempt to reduce the feature space and simplify the information required for the model to learn. In the code cell below, you will need to implement the following: \n",
    "- Use the model that you found from grid search\n",
    "- Train it on the same training set with only the top five important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIsK02FwGk8V"
   },
   "outputs": [],
   "source": [
    "# Import functionality for cloning a model\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Reduce the feature space\n",
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "\n",
    "# Train on the model that you found from grid search earlier\n",
    "# put your best model here. It should be 'clf' if you do not modify its name\n",
    "clf_regular = None    \n",
    "# clone the classifier such that both classifier has same configurations\n",
    "clf_reduced = clone(clf_regular)    \n",
    "\n",
    "# TODO: fit clf_redgular with data that have all features\n",
    "\n",
    "# TODO: fit clf_reduced with data which only contains top five features\n",
    "\n",
    "\n",
    "# Report scores from the final model using both versions of data\n",
    "print(\"\\nModel trained on regular data\\n------\")\n",
    "print(\"Model has a training F1 score of {:.4f}.\".format(predict_labels(clf_regular, X_train, y_train)))\n",
    "print(\"Model has a testing F1 score of {:.4f}.\".format(predict_labels(clf_regular, X_test, y_test)))\n",
    "print(\"\\nFinal Model trained on reduced data\\n------\")\n",
    "print(\"Model has a training F1 score of {:.4f}.\".format(predict_labels(clf_reduced, X_train_reduced, y_train)))\n",
    "print(\"Model has a testing F1 score of {:.4f}.\".format(predict_labels(clf_reduced, X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "327YqTHRKlY-"
   },
   "source": [
    "### **Question 10** - Effects of Feature Selection\n",
    "*How does the final model's F-score on the reduced data using only five features compare to those same scores when all features are used? If training time was a factor, would you consider using the reduced data as your training set?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNerg3fnK40R"
   },
   "source": [
    "**Answer:** *Replace this text with your answer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKl_rMFntrWr"
   },
   "source": [
    "At last, convert this ipynb file to a html file and submit it with all codes and figures included."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "student_intervention_sheet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
